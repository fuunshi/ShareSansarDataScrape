name: Run Spider

on:
  push:
    branches:
      - master
  schedule:
    - cron: '15 11 * * *' # Run the job every day at 11:15 AM UTC => 5:00 Nepal Time

jobs:
  run_spider:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Cache dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-poetry-${{ hashFiles('**/poetry.lock') }}
        restore-keys: |
          ${{ runner.os }}-poetry-

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Run spider
      run: scrapy crawl market

    - name: Commit and Push Files
      run: |
        git config --local user.email "pranilshrestha2016@gmail.com"
        git config --local user.name "fuunshi"
        git add .
        git commit -am "Share data has been successfully scrapped"
        git push origin master